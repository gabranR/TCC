{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a debugging file for the scraping actions\n",
    "<br>\n",
    "\n",
    "\n",
    "<br>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second file: Scraping the Reviews\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/atrat_links.csv')\n",
    "links = data['Links']\n",
    "cookie_page = 'https://www.tripadvisor.com.br/'\n",
    "#just saving this here for better readability\n",
    "nxt_css_select = '.cCnaz > div:nth-child(1) > a:nth-child(1) > svg:nth-child(1)'\n",
    "\n",
    "## Part 01: Getting the links and selecting the attractions ------------\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ToDo:\n",
    "GET:\n",
    "\n",
    "- a) the link to each profile for the ids\n",
    "- b) número de contribuições\n",
    "- c) nota (title da tag svg)\n",
    "- d) data da avaliação\n",
    "- e) data da viagem\n",
    "- f) local de origem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "option = Options()\n",
    "option.headless = False\n",
    "driver = webdriver.Firefox(options=option)\n",
    "\n",
    "## Gettiing da cookie... the smart way --- \n",
    "driver.get(links[41])\n",
    "driver.implicitly_wait(10)\n",
    "driver.find_element_by_xpath('//*[@id=\"onetrust-pc-btn-handler\"]').click()\n",
    "time.sleep(1)\n",
    "driver.find_element_by_xpath('/html/body/div[2]/div[4]/div[3]/div[1]/button[1]').click()\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "# click in 'all languagesss'\n",
    "\n",
    "driver.find_element_by_xpath('/html/body/div[1]/main/div[1]/div[2]/div[2]/div/div/span/section[8]/div/div/span/section/section/div[1]/div/div[1]/div/div[2]/div/div/span[2]/span/div/div/button').click()\n",
    "time.sleep(2)\n",
    "driver.find_element_by_xpath('//*[@id=\"menu-item-all\"]').click()\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "\n",
    "##uhhhh so fancy using classes... OOP uhhh =======\n",
    "# The ideia here is to create a commom set of attributes that can be used by the methods, and then I can create objects requesting specific tags\n",
    "\n",
    "class Scraper:\n",
    "    #making the constructor, those are all the parameters I need to navigate and get one info at a time\n",
    "    def __init__(self, element_css, soup_tag, soup_class, soup_attr):\n",
    "        self.element_css = element_css\n",
    "        self.soup_tag = soup_tag\n",
    "        self.soup_class  = soup_class\n",
    "        self.soup_attr = soup_attr\n",
    "    # Just a function to return false when there is no 'next' button anymore\n",
    "    def stop_pag(self):\n",
    "        temp = bool(driver.find_elements_by_css_selector(nxt_css_select))\n",
    "        return temp\n",
    "\n",
    "    ## Função para encontrar *os elementos*, salvar o html, parsear o html e retornar uma lista com o texto do elemento\n",
    "    # no momento suporta texto e href, mas caso precise de outra informação é só incluir mais um elif\n",
    "    def find_each(self):\n",
    "        lista = []\n",
    "        element = driver.find_elements_by_css_selector(self.element_css)\n",
    "        if self.soup_attr == 'href':\n",
    "            for i in element:\n",
    "                html = i.get_attribute('innerHTML')\n",
    "                soup = BeautifulSoup(html, 'lxml')\n",
    "                lista.append(soup.find(self.soup_tag, self.soup_class)['href'])\n",
    "        elif self.soup_attr == 'text':\n",
    "            for i in element:\n",
    "                html = i.get_attribute('innerHTML')\n",
    "                soup = BeautifulSoup(html, 'lxml')\n",
    "                lista.append(soup.find(self.soup_tag, self.soup_class).text)\n",
    "        else:\n",
    "            raise ValueError(\"Você passou o argumento errado, soup_attr recebe 'href' ou 'text'.\")\n",
    "        return lista\n",
    "    ## A METHOD TO RULE THEM ALL =====\n",
    "    # This method creates the iteration of the action of clicking on the next button, and also extends the list - consolidates - all info\n",
    "    def give_me_info(self):\n",
    "        aa = []    \n",
    "        while self.stop_pag():\n",
    "            aa.extend(self.find_each())\n",
    "            driver.find_element_by_css_selector(nxt_css_select).click()\n",
    "            time.sleep(2)\n",
    "        else:\n",
    "            aa.extend(self.find_each())\n",
    "        return aa    \n",
    "\n",
    "## Creating the objects with the specific selectors, tags and etc to be called later with the give_me_info function\n",
    "user_id = Scraper(\n",
    "    element_css = '.dHjBB span span[data-ft]',\n",
    "    soup_tag = 'a',\n",
    "    soup_class = 'iPqaD _F G- ddFHE eKwUx btBEK fUpii',\n",
    "    soup_attr = 'href' \n",
    ")\n",
    "\n",
    "bb = user_id.give_me_info()\n",
    "bb = [re.sub('\\/Profile\\/', '', i) for i in bb]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'erikabritoa'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb1 = [re.sub('\\/Profile\\/', '', i) for i in bb]\n",
    "print(len(bb1))\n",
    "bb1[-6]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f3cef28238c25641b9601de891cf85fa5f544bfe0130becece889e10fbca7396"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
